{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "BASE_URL = \"https://www.googleapis.com/youtube/v3/commentThreads\"\n",
    "\n",
    "\n",
    "async def fetch_all_comments(video_id):\n",
    "     # Load environment variables from .env file\n",
    "    load_dotenv()\n",
    "\n",
    "    # Now you can access your environment variables using os.getenv()\n",
    "    YT_API_KEY = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        while True:\n",
    "            params = {\n",
    "                \"part\": \"snippet\",\n",
    "                \"videoId\": video_id,\n",
    "                \"maxResults\": 100,\n",
    "                \"key\": YT_API_KEY,\n",
    "                \"pageToken\": next_page_token\n",
    "            }\n",
    "            response = await client.get(BASE_URL, params=params)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                for item in data.get(\"items\", []):\n",
    "                    top_comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "                    comments.append({\n",
    "                        \"author\": top_comment[\"authorDisplayName\"],\n",
    "                        \"text\": top_comment[\"textOriginal\"],\n",
    "                        \"likeCount\": top_comment.get(\"likeCount\", 0),\n",
    "                        \"publishedAt\": top_comment[\"publishedAt\"]\n",
    "                    })\n",
    "                next_page_token = data.get(\"nextPageToken\")\n",
    "                if not next_page_token:\n",
    "                    break\n",
    "            else:\n",
    "                raise Exception(f\"Failed to fetch comments: {response.status_code} - {response.text}\")\n",
    "\n",
    "    return comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of comments fetched: 500\n",
      "First 5 most liked comments:\n",
      "1. Author: @DedicatedSpirit8\n",
      "   Comment: I love Charlie&#39;s passion<br>Life is purposeless.<br>To die sith a full bank account and regreets is waaay worse than dying penniless but fulfilled.\n",
      "   Likes: 121\n",
      "   Published at: 2025-01-19T10:06:30Z\n",
      "----------------------------------------\n",
      "2. Author: @IcyPandazzz\n",
      "   Comment: My friend, flying is BY FAR the safest mode of transportation that humans have. You&#39;re more likely to get eaten by a shark than suffer a single injury during flight. Being eaten by a shark is so rare that you&#39;re more likely to be struck by lightning... TWICE in your lifetime. To add a cherry on top, there is a 63% chance that you will get into at least 3 car accidents by the age of 55. Flight technology is also so advanced that the planes literally fly themselves PERFECTLY! The only reason to have a pilot anymore for the bigger travel companies is to make sure that the plane&#39;s computers are all functioning properly and if they mess up, EXTREMELY rarely btw, to take over flight control. You got this Charlie nothing to be afraid of!!!\n",
      "   Likes: 22\n",
      "   Published at: 2025-01-19T02:33:46Z\n",
      "----------------------------------------\n",
      "3. Author: @Liam.Fairhurst\n",
      "   Comment: Been following you since the early days (back when you was too shy for the camera) <br><br>It‚Äôs a blessing to have followed your journey since then. You are single handily THE best content creator out there.<br><br>People like yourself and the LA Beast are the reasons I love the internet. The good guys out there\n",
      "   Likes: 14\n",
      "   Published at: 2025-01-19T09:08:06Z\n",
      "----------------------------------------\n",
      "4. Author: @Aetheretic\n",
      "   Comment: Imagine just being able to blow 4.2 mill and be completely unfazed. Imagine being able to buy anything you think is cool and you want without a care, while most of us watching are broke and struggling to buy groceries. Must be nice. Fucking nuts.\n",
      "   Likes: 9\n",
      "   Published at: 2025-01-19T01:53:22Z\n",
      "----------------------------------------\n",
      "5. Author: @kevinguillemette2710\n",
      "   Comment: Charlie doing the sodapoppin PYAH üòÇüòÇüòÇ I&#39;M DYING üòÇüòÇüòÇ\n",
      "   Likes: 4\n",
      "   Published at: 2025-01-19T03:48:59Z\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "async def test_fetch_all_comments():\n",
    "    video_id = \"jAoIOIjMZM0\"  # Replace with an actual YouTube video ID\n",
    "\n",
    "    # Fetch the comments\n",
    "    comments = await fetch_all_comments(video_id)\n",
    "\n",
    "    # Sort comments by number of likes (in descending order)\n",
    "    comments_sorted = sorted(comments, key=lambda x: x['likeCount'], reverse=True)\n",
    "\n",
    "    # Print the number of comments\n",
    "    print(f\"Total number of comments fetched: {len(comments)}\")\n",
    "\n",
    "    # Print some of the fetched comments (for example, the first 5 most liked ones)\n",
    "    print(\"First 5 most liked comments:\")\n",
    "    for i, comment in enumerate(comments_sorted[:5]):\n",
    "        print(f\"{i+1}. Author: {comment['author']}\")\n",
    "        print(f\"   Comment: {comment['text']}\")\n",
    "        print(f\"   Likes: {comment['likeCount']}\")\n",
    "        print(f\"   Published at: {comment['publishedAt']}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "\n",
    "load_dotenv()  # Make sure to load environment variables\n",
    "await test_fetch_all_comments() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Comments:\n",
      "The YouTube comments mainly focus on the phrase \"talk this\" and the $4.2 million that the YouTuber, Charlie, spent on his e-sports team. Viewers found the fact that Charlie could finally \"talk this\" amusing, and it became a running joke. Additionally, they admired Charlie's financial commitment to e-sports, considering his massive expenditure a casual show of wealth. They also appreciate his passionate dedication to his team, despite facing economic losses. Lastly, comments indicate some excitement over a typo on the video title and Charlie's video content related to the e-sports scene. Some viewers also expressed their appreciation for the improved lighting in the display case and the performance of Charlie's team in different games. Overall, the general sentiment is supportive and amused by Charlie's antics.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# Summarize comments function\n",
    "async def summarize_comments(video_id):\n",
    "    # Fetch comments\n",
    "    comments = await fetch_all_comments(video_id)\n",
    "\n",
    "    # Sort comments by likes\n",
    "    comments_sorted = sorted(comments, key=lambda x: x['likeCount'], reverse=True)\n",
    "\n",
    "    # Prepare prompt with weighted comments\n",
    "    prompt = \"Summarize the following YouTube comments. Comments with more likes are more important:\\n\\n\"\n",
    "    for comment in comments_sorted[:50]:  # Include top 50 comments for the prompt\n",
    "        prompt += f\"- [{comment['likeCount']} likes] {comment['text']}\\n\"\n",
    "\n",
    "    # Initialize OpenAI API\n",
    "    load_dotenv()\n",
    "    client = OpenAI(api_key=os.getenv(\"THREAD_OPENAI_API_KEY\"))\n",
    "\n",
    "    # Summarize using GPT\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert summarizer.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Print the summary\n",
    "    summary = response.choices[0].message.content\n",
    "    return summary, comments_sorted\n",
    "\n",
    "summary, comments = await summarize_comments(\"jAoIOIjMZM0\")\n",
    "print(\"\\nSummary of Comments:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "Total valid texts: 6857\n",
      "üì§ Sending batch of 2048 texts (43208 tokens)\n",
      "üì§ Sending batch of 2048 texts (37447 tokens)\n",
      "üì§ Sending batch of 2048 texts (30087 tokens)\n",
      "üì§ Sending final batch of 713 texts (5567 tokens)\n",
      "‚úÖ Total embeddings generated: 6857\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import re\n",
    "import tiktoken\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"THREAD_OPENAI_API_KEY\"))\n",
    "\n",
    "def clean_text(text):\n",
    "    return re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)  # Strip non-ASCII characters\n",
    "\n",
    "def is_valid_comment(text, encoder, max_tokens=8192, max_chars=10000):\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return False\n",
    "    if len(text) > max_chars:\n",
    "        return False\n",
    "    try:\n",
    "        text.encode(\"utf-8\")\n",
    "    except UnicodeEncodeError:\n",
    "        return False\n",
    "    if len(encoder.encode(text)) > max_tokens:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def vectorize_comments(comments):\n",
    "    encoder = tiktoken.encoding_for_model(\"text-embedding-3-small\")\n",
    "\n",
    "    # Preprocess and validate\n",
    "    texts = []\n",
    "    for comment in comments:\n",
    "        raw = comment.get(\"text\", \"\")\n",
    "        cleaned = clean_text(str(raw)).strip()\n",
    "        if is_valid_comment(cleaned, encoder):\n",
    "            texts.append(cleaned)\n",
    "        else:\n",
    "            print(f\"‚ùå Skipped invalid comment: {repr(cleaned)[:100]}\")\n",
    "\n",
    "    if not texts:\n",
    "        raise ValueError(\"No valid comment text to embed.\")\n",
    "\n",
    "    print(\"Total valid texts:\", len(texts))\n",
    "\n",
    "    # Batch constraints\n",
    "    MAX_TOKENS_PER_TEXT = 8192\n",
    "    MAX_TOKENS_PER_BATCH = 300_000\n",
    "    MAX_TEXTS_PER_BATCH = 2048\n",
    "\n",
    "    current_batch = []\n",
    "    current_token_count = 0\n",
    "    embeddings = []\n",
    "\n",
    "    for text in texts:\n",
    "        tokens = len(encoder.encode(text))\n",
    "\n",
    "        if (current_token_count + tokens > MAX_TOKENS_PER_BATCH) or (len(current_batch) >= MAX_TEXTS_PER_BATCH):\n",
    "            print(f\"üì§ Sending batch of {len(current_batch)} texts ({current_token_count} tokens)\")\n",
    "            try:\n",
    "                response = client.embeddings.create(\n",
    "                    input=current_batch,\n",
    "                    model=\"text-embedding-3-small\"\n",
    "                )\n",
    "                embeddings.extend([np.array(item.embedding) for item in response.data])\n",
    "            except Exception as e:\n",
    "                print(\"‚ùå Batch failed. Dumping inputs:\")\n",
    "                for i, item in enumerate(current_batch):\n",
    "                    print(f\"[{i}] ({len(item)} chars): {repr(item[:80])}\")\n",
    "                raise e\n",
    "            current_batch = []\n",
    "            current_token_count = 0\n",
    "\n",
    "        current_batch.append(text)\n",
    "        current_token_count += tokens\n",
    "\n",
    "    # Final batch\n",
    "    if current_batch:\n",
    "        print(f\"üì§ Sending final batch of {len(current_batch)} texts ({current_token_count} tokens)\")\n",
    "        response = client.embeddings.create(\n",
    "            input=current_batch,\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "        embeddings.extend([np.array(item.embedding) for item in response.data])\n",
    "\n",
    "    print(f\"‚úÖ Total embeddings generated: {len(embeddings)}\")\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def search_similar_comments(question, embeddings, comments, top_k=5):\n",
    "    # Embed the question\n",
    "    response = client.embeddings.create(\n",
    "        input=[question],\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    question_vector = np.array(response.data[0].embedding)\n",
    "\n",
    "    # Normalize vectors for cosine similarity\n",
    "    q_norm = question_vector / np.linalg.norm(question_vector)\n",
    "    comment_vectors = [e / np.linalg.norm(e) for e in embeddings]\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    similarities = [(i, np.dot(q_norm, e)) for i, e in enumerate(comment_vectors)]\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return top_k matching comments\n",
    "    top_indices = [i for i, _ in similarities[:top_k]]\n",
    "    return [comments[i] for i in top_indices]\n",
    "\n",
    "\n",
    "summary, comments = await summarize_comments(\"jAoIOIjMZM0\")\n",
    "\n",
    "embeddings = vectorize_comments(comments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Skipped invalid comment: ''\n",
      "Total valid texts: 499\n",
      "üì§ Sending final batch of 499 texts (9483 tokens)\n",
      "‚úÖ Total embeddings generated: 499\n",
      "\n",
      "Top 5 Similar Comments:\n",
      "1. Author: @sadganonkiller\n",
      "   Comment: the money is in the venues. think having your own stadium, for your team, like football teams do, would really open more doors\n",
      "   Likes: 0\n",
      "   Published at: 2025-01-19T02:39:40Z\n",
      "----------------------------------------\n",
      "2. Author: @xxsodomaruxx\n",
      "   Comment: \"The eSports organization formally known as Moist\"\n",
      "   Likes: 0\n",
      "   Published at: 2025-01-19T23:34:34Z\n",
      "----------------------------------------\n",
      "3. Author: @boostedn\n",
      "   Comment: Start a CS team üí™\n",
      "   Likes: 1\n",
      "   Published at: 2025-01-19T16:17:01Z\n",
      "----------------------------------------\n",
      "4. Author: @srdjan455\n",
      "   Comment: Ok but why is eSports such a big money sink?\n",
      "   Likes: 0\n",
      "   Published at: 2025-01-21T15:33:27Z\n",
      "----------------------------------------\n",
      "5. Author: @dokgohyuk3753\n",
      "   Comment: Genuine question, how much money is the company down? Did you directly loose 4.2 million? Or is that how much of a hole the company is in\n",
      "   Likes: 0\n",
      "   Published at: 2025-01-19T17:10:39Z\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary, comments = await summarize_comments(\"jAoIOIjMZM0\")\n",
    "\n",
    "top_comments = comments[:500]\n",
    "\n",
    "embeddings = vectorize_comments(top_comments)\n",
    "\n",
    "question = \"How much money did he spend or lose on Moist Esports?\"\n",
    "\n",
    "similar_comments = search_similar_comments(question, embeddings, top_comments)\n",
    "\n",
    "# Print out the similar comments\n",
    "print(\"\\nTop 5 Similar Comments:\")\n",
    "for i, comment in enumerate(similar_comments):\n",
    "    print(f\"{i+1}. Author: {comment['author']}\")\n",
    "    print(f\"   Comment: {comment['text']}\")\n",
    "    print(f\"   Likes: {comment['likeCount']}\")\n",
    "    print(f\"   Published at: {comment['publishedAt']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "‚ùå Skipped invalid comment: ''\n",
      "Total valid texts: 6855\n",
      "üì§ Sending batch of 2048 texts (39570 tokens)\n",
      "üì§ Sending batch of 2048 texts (34009 tokens)\n",
      "üì§ Sending batch of 2048 texts (27824 tokens)\n",
      "üì§ Sending final batch of 711 texts (4885 tokens)\n",
      "‚úÖ Total embeddings generated: 6855\n",
      "Based on the summary, Charlie invested $4.2 million in his esports team, Moist Esports.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"THREAD_OPENAI_API_KEY\"))\n",
    "\n",
    "def generate_answer(question, relevant_comments, summary):\n",
    "    relevant_text = \"\\n\".join([f\"- {comment['text']}\" for comment in relevant_comments])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Video Summary:\n",
    "    {summary}\n",
    "\n",
    "    Related Comments:\n",
    "    {relevant_text}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Based on the summary and related comments, please provide an answer.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "summary, comments = await summarize_comments(\"jAoIOIjMZM0\")\n",
    "\n",
    "top_comments = comments[:500]\n",
    "\n",
    "embeddings = vectorize_comments(top_comments)\n",
    "\n",
    "question = \"How much money did he spend or lose on Moist Esports?\"\n",
    "\n",
    "similar_comments = search_similar_comments(question, embeddings, top_comments)\n",
    "\n",
    "response = generate_answer(question, similar_comments, summary)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thread_sum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
